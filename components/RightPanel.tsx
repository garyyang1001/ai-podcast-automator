import React, { useState, useCallback } from 'react';
import { Speaker, SeoMeta, ScriptMode, DialogLine } from '../types';
import { 
  AVAILABLE_VOICES, 
  GEMINI_MODEL_TEXT,
  EMOTION_OPTIONS,
  PACE_OPTIONS,
  TONE_OPTIONS,
  STYLE_OPTIONS
} from '../constants';
import { Button, Select, TextInput } from './shared/FormControls';
import { ChevronDownIcon, ChevronUpIcon, Cog8ToothIcon, DocumentTextIcon, MusicalNoteIcon, UserIcon, UsersIcon, SparklesIcon, PlayCircleIcon, ClockIcon } from './icons/HeroIcons';
import { Spinner } from './shared/Spinner';
import { GoogleGenAI } from '@google/genai';

import JSZip from 'jszip';

// ---- Local helper type ----
type SynthesizedAudio = { data: string; mimeType: string };

interface RightPanelProps {
  scriptMode: ScriptMode;
  setScriptMode: (mode: ScriptMode) => void;
  speakers: Speaker[];
  updateSpeaker: (index: number, speaker: Speaker) => void;
  onGenerateScript: () => void;
  onGenerateSeoMeta: () => void;
  onDownloadScriptText: () => void;
  onDownloadTimedTranscriptSrt: () => void;
  seoMeta: SeoMeta | null;
  rssFeedUrl: string;
  setRssFeedUrl: (url: string) => void;
  isLoading: boolean; 
  isSynthesizingAudio: boolean; 
  setIsSynthesizingAudio: (loading: boolean) => void; 
  setError: (message: string | null) => void;
  dialogLines: DialogLine[];
  actualAudioDurations: Record<string, number>;
  panelHeightClass?: string; 
  onAudioSegmentSynthesized: (lineId: string, duration: number) => void;
}

const getEnvVar = (key: string): string | undefined => {
  if (typeof window !== 'undefined') {
    return (window as any)?.env?.[key] || (import.meta as any)?.env?.[`VITE_${key}`] || (import.meta as any)?.env?.[key];
  }
  return process.env[key] || process.env[`VITE_${key}`];
};

// ğŸ†• å»ºç«‹èªéŸ³æŒ‡ç¤ºå‡½æ•¸
const buildVoiceInstruction = (speaker: Speaker): string => {
  const instructions: string[] = [];
  
  // æƒ…ç·’æ˜ å°„
  const emotionMap: Record<string, string> = {
    'excited': 'sound excited and energetic',
    'calm': 'sound calm and peaceful',
    'professional': 'sound professional and authoritative',
    'friendly': 'sound friendly and warm',
    'enthusiastic': 'sound enthusiastic and passionate'
  };
  
  // èªé€Ÿæ˜ å°„
  const paceMap: Record<string, string> = {
    'very-slow': 'speak very slowly and clearly',
    'slow': 'speak slowly',
    'fast': 'speak at a fast pace while remaining clear',
    'very-fast': 'speak as fast as possible while remaining intelligible'
  };
  
  // éŸ³èª¿æ˜ å°„
  const toneMap: Record<string, string> = {
    'low': 'use a lower pitch',
    'high': 'use a higher pitch'
  };
  
  // é¢¨æ ¼æ˜ å°„
  const styleMap: Record<string, string> = {
    'whisper': 'speak in a gentle whisper',
    'strong': 'speak with strong emphasis',
    'gentle': 'speak gently and softly'
  };
  
  // çµ„åˆæŒ‡ç¤º
  if (speaker.emotion && speaker.emotion !== 'neutral') {
    instructions.push(emotionMap[speaker.emotion]);
  }
  if (speaker.pace && speaker.pace !== 'normal') {
    instructions.push(paceMap[speaker.pace]);
  }
  if (speaker.tone && speaker.tone !== 'normal') {
    instructions.push(toneMap[speaker.tone]);
  }
  if (speaker.style && speaker.style !== 'normal') {
    instructions.push(styleMap[speaker.style]);
  }
  
  return instructions.length > 0 ? `Make ${speaker.name} ${instructions.join(', ')}.` : '';
};

// ä¿®æ­£ï¼šæ·»åŠ  PCM åˆ° WAV è½‰æ›å‡½æ•¸
const convertPCMToWAV = (pcmData: Uint8Array, sampleRate: number = 24000, channels: number = 1, bitDepth: number = 16): Uint8Array => {
  const dataLength = pcmData.length;
  const buffer = new ArrayBuffer(44 + dataLength);
  const view = new DataView(buffer);
  
  // WAV header
  const writeString = (offset: number, string: string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  };
  
  writeString(0, 'RIFF');                        // ChunkID
  view.setUint32(4, 36 + dataLength, true);     // ChunkSize
  writeString(8, 'WAVE');                       // Format
  writeString(12, 'fmt ');                      // Subchunk1ID
  view.setUint32(16, 16, true);                 // Subchunk1Size
  view.setUint16(20, 1, true);                  // AudioFormat (PCM)
  view.setUint16(22, channels, true);           // NumChannels
  view.setUint32(24, sampleRate, true);         // SampleRate
  view.setUint32(28, sampleRate * channels * bitDepth / 8, true); // ByteRate
  view.setUint16(32, channels * bitDepth / 8, true);              // BlockAlign
  view.setUint16(34, bitDepth, true);           // BitsPerSample
  writeString(36, 'data');                      // Subchunk2ID
  view.setUint32(40, dataLength, true);         // Subchunk2Size
  
  // PCM data
  const uint8Array = new Uint8Array(buffer);
  uint8Array.set(pcmData, 44);
  
  return uint8Array;
};

const AccordionSection: React.FC<{ title: string, icon?: React.ReactNode, children: React.ReactNode, defaultOpen?: boolean, id?: string }> = ({ title, icon, children, defaultOpen = false, id }) => {
  const [isOpen, setIsOpen] = useState(defaultOpen);
  const sectionId = id || `accordion-${title.replace(/\s+/g, '-').toLowerCase()}`;
  return (
    <div className="border border-slate-700 rounded-lg">
      <button
        onClick={() => setIsOpen(!isOpen)}
        className="w-full flex justify-between items-center p-3 bg-slate-800 hover:bg-slate-750 transition-colors rounded-t-lg"
        aria-expanded={isOpen}
        aria-controls={sectionId}
      >
        <div className="flex items-center">
          {icon && <span className="mr-2">{icon}</span>}
          <span className="font-semibold text-slate-200">{title}</span>
        </div>
        {isOpen ? <ChevronUpIcon className="w-5 h-5 text-slate-400" /> : <ChevronDownIcon className="w-5 h-5 text-slate-400" />}
      </button>
      {isOpen && <div id={sectionId} className="p-4 bg-slate-850 rounded-b-lg space-y-3">{children}</div>}
    </div>
  );
};

export const RightPanel: React.FC<RightPanelProps> = ({
  scriptMode,
  setScriptMode,
  speakers,
  updateSpeaker,
  onGenerateScript,
  onGenerateSeoMeta,
  onDownloadScriptText,
  onDownloadTimedTranscriptSrt,
  seoMeta,
  rssFeedUrl,
  setRssFeedUrl,
  isLoading,
  isSynthesizingAudio,
  setIsSynthesizingAudio,
  setError,
  dialogLines,
  actualAudioDurations,
  panelHeightClass,
  onAudioSegmentSynthesized,
}) => {
  // åªé‡å°ã€Œæ­£åœ¨èªéŸ³é è¦½çš„ç™¼è¨€äººã€çš„ indexï¼›null ä»£è¡¨ç›®å‰æ²’æœ‰åœ¨é è¦½
  const [previewingSpeakerIndex, setPreviewingSpeakerIndex] = useState<number | null>(null);
  
  const handleSpeakerChange = (index: number, field: keyof Omit<Speaker, 'id'|'color'|'dotColor'>, value: string) => {
    updateSpeaker(index, { ...speakers[index], [field]: value });
  };

  // ğŸ”„ ä¿®æ”¹å¾Œçš„èªéŸ³åˆæˆå‡½æ•¸ - æ”¯æ´èªéŸ³æŒ‡ç¤º
  const synthesizeWithGeminiTTS = useCallback(async (text: string, speaker: Speaker): Promise<SynthesizedAudio | null> => {
    const geminiApiKey = getEnvVar('API_KEY');

    if (!geminiApiKey) {
      setError("Gemini API Key (API_KEY) æœªæ‰¾åˆ°ã€‚è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š VITE_API_KEYã€‚");
      return null;
    }

    try {
      const ai = new GoogleGenAI({ apiKey: geminiApiKey });
      
      // ğŸ†• å»ºç«‹èªéŸ³æŒ‡ç¤º
      const voiceInstruction = buildVoiceInstruction(speaker);
      const enhancedText = voiceInstruction ? `${voiceInstruction}\n\n"${text}"` : text;
      
      const response = await ai.models.generateContent({
        model: "gemini-2.5-flash-preview-tts",
        contents: [{ parts: [{ text: enhancedText }] }],
        config: {
          responseModalities: ['Audio'],
          speechConfig: {
            voiceConfig: {
              prebuiltVoiceConfig: { voiceName: speaker.voice },
            },
          },
        },
      });

      const inlineData = response.candidates?.[0]?.content?.parts?.[0]?.inlineData;
      if (inlineData?.data) {
        return { 
          data: inlineData.data, 
          mimeType: inlineData.mimeType || 'audio/L16;codec=pcm;rate=24000'
        };
      } else {
        console.error("Gemini TTS API æ²’æœ‰è¿”å›é æœŸçš„éŸ³é »å…§å®¹:", response);
        throw new Error("Gemini TTS API æ²’æœ‰è¿”å›éŸ³é »å…§å®¹ã€‚");
      }
    } catch (e) {
      console.error("Gemini TTS èªéŸ³åˆæˆéŒ¯èª¤:", e);
      throw e;
    }
  }, [setError]);

  // ğŸ”„ ä¿®æ”¹å¾Œçš„å¤šäººå°è©±åˆæˆå‡½æ•¸ - æ”¯æ´èªéŸ³æŒ‡ç¤º
  const synthesizeMultiSpeakerWithGemini = useCallback(async (dialogLines: DialogLine[], speakers: Speaker[]): Promise<SynthesizedAudio | null> => {
    const geminiApiKey = getEnvVar('API_KEY');

    if (!geminiApiKey) {
      setError("Gemini API Key (API_KEY) æœªæ‰¾åˆ°ã€‚");
      return null;
    }

    const script = dialogLines.map(line => {
      const speaker = speakers.find(s => s.id === line.speakerId);
      return `${speaker?.name || 'Speaker'}: ${line.text}`;
    }).join('\n');

    const activeSpeakers = scriptMode === ScriptMode.SINGLE ? [speakers[0]] : speakers.slice(0, 2);
    
    // ğŸ†• å»ºç«‹æ¯å€‹ç™¼è¨€äººçš„èªéŸ³æŒ‡ç¤º
    const speakerInstructions = activeSpeakers
      .map(speaker => buildVoiceInstruction(speaker))
      .filter(instruction => instruction.length > 0);
    
    // ğŸ†• çµ„åˆå®Œæ•´çš„æç¤ºè©
    let enhancedPrompt = '';
    if (speakerInstructions.length > 0) {
      enhancedPrompt = `${speakerInstructions.join(' ')}\n\n`;
    }
    enhancedPrompt += `TTS the following conversation between ${activeSpeakers.map(s => s.name).join(' and ')}:\n${script}`;

    const speakerConfigs = activeSpeakers.map(speaker => ({
      speaker: speaker.name,
      voiceConfig: {
        prebuiltVoiceConfig: { voiceName: speaker.voice }
      }
    }));

    try {
      const ai = new GoogleGenAI({ apiKey: geminiApiKey });
      
      const response = await ai.models.generateContent({
        model: "gemini-2.5-flash-preview-tts",
        contents: [{ parts: [{ text: enhancedPrompt }] }],
        config: {
          responseModalities: ['Audio'],
          speechConfig: {
            multiSpeakerVoiceConfig: {
              speakerVoiceConfigs: speakerConfigs
            }
          }
        }
      });

      const inlineData = response.candidates?.[0]?.content?.parts?.[0]?.inlineData;
      if (inlineData?.data) {
        return { 
          data: inlineData.data, 
          mimeType: inlineData.mimeType || 'audio/L16;codec=pcm;rate=24000'
        };
      } else {
        throw new Error("Gemini TTS æ²’æœ‰è¿”å›éŸ³é »å…§å®¹ã€‚");
      }
    } catch (e) {
      console.error("Gemini å¤šäººå°è©± TTS éŒ¯èª¤:", e);
      throw e;
    }
  }, [setError, scriptMode]);

  const synthesizeSpeechInternal = useCallback(async (text: string, speaker: Speaker): Promise<SynthesizedAudio | null> => {
    return await synthesizeWithGeminiTTS(text, speaker);
  }, [synthesizeWithGeminiTTS]);

  const handlePreviewVoice = useCallback(async (speakerIndex: number) => {
    const speaker = speakers[speakerIndex];
    if (!speaker || isSynthesizingAudio) return;
    setPreviewingSpeakerIndex(speakerIndex);
    setIsSynthesizingAudio(true);
    setError(null);

    const voiceOption = AVAILABLE_VOICES.find(v => v.id === speaker.voice);
    const voiceStyleName = voiceOption ? voiceOption.name : "é è¨­é¢¨æ ¼";
    const speakerName = speaker.name || `ç™¼è¨€äºº ${speakerIndex + 1}`;
    
    // ğŸ†• æ ¹æ“šèªéŸ³è¨­å®šèª¿æ•´é è¦½æ–‡å­—
    let previewText = `é€™æ˜¯ ${speakerName} ä½¿ç”¨ ${voiceStyleName} çš„èªéŸ³é è¦½ã€‚`;
    
    // æ ¹æ“šæƒ…ç·’èª¿æ•´é è¦½å…§å®¹
    switch (speaker.emotion) {
      case 'excited':
        previewText += "æˆ‘æ„Ÿåˆ°éå¸¸èˆˆå¥®ï¼é€™å€‹èªéŸ³æ•ˆæœçœŸæ˜¯å¤ªæ£’äº†ï¼";
        break;
      case 'calm':
        previewText += "è®“æˆ‘å€‘ä»¥å¹³éœçš„å¿ƒæƒ…ä¾†é«”é©—é€™å€‹ç¾å¥½çš„èªéŸ³æ•ˆæœã€‚";
        break;
      case 'professional':
        previewText += "æ ¹æ“šå°ˆæ¥­åˆ†æï¼Œé€™æ˜¯ä¸€å€‹é«˜å“è³ªçš„èªéŸ³åˆæˆæŠ€è¡“ã€‚";
        break;
      case 'friendly':
        previewText += "å¾ˆé«˜èˆˆèˆ‡æ‚¨åˆ†äº«é€™å€‹å‹å–„æº«æš–çš„èªéŸ³é«”é©—ã€‚";
        break;
      case 'enthusiastic':
        previewText += "è®“æˆ‘å€‘ä¸€èµ·ç†±æƒ…åœ°æ¢ç´¢é€™å€‹é©šäººçš„èªéŸ³æŠ€è¡“ï¼";
        break;
      default:
        previewText += "æ‚¨å¥½ï¼Œé€™æ˜¯ç”± Gemini AI åŸç”ŸèªéŸ³æŠ€è¡“ç”¢ç”Ÿçš„é«˜å“è³ªèªéŸ³ã€‚";
    }
    
    try {
        const synthesized = await synthesizeSpeechInternal(previewText, speaker);
        if (synthesized) {
            const byteCharacters = atob(synthesized.data);
            const pcmData = new Uint8Array(byteCharacters.length);
            for (let i = 0; i < byteCharacters.length; i++) {
              pcmData[i] = byteCharacters.charCodeAt(i);
            }
            
            const wavData = convertPCMToWAV(pcmData);
            const blob = new Blob([wavData], { type: 'audio/wav' });
            const audioSrc = URL.createObjectURL(blob);
            const audio = new Audio(audioSrc);
            audio.play().catch(e => {
                console.error("æ’­æ”¾éŸ³é »éŒ¯èª¤:", e);
                setError("ç„¡æ³•æ’­æ”¾é è¦½èªéŸ³ï¼Œç€è¦½å™¨å¯èƒ½é™åˆ¶äº†è‡ªå‹•æ’­æ”¾ã€‚");
            });
        }
    } catch (e) {
        setError(e instanceof Error ? e.message : "èªéŸ³é è¦½åˆæˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ã€‚");
    } finally {
        setPreviewingSpeakerIndex(null);
        setIsSynthesizingAudio(false);
    }
  }, [speakers, synthesizeSpeechInternal, setError, isSynthesizingAudio, setIsSynthesizingAudio]);

  const handleGenerateFullPodcastAudio = useCallback(async () => {
    if (dialogLines.length === 0) {
      setError("è«‹å…ˆç”Ÿæˆè…³æœ¬æ‰èƒ½ç”¢ç”ŸèªéŸ³ã€‚");
      return;
    }

    setIsSynthesizingAudio(true);
    setError(null);

    try {
      if (scriptMode === ScriptMode.MULTI && speakers.length <= 2) {
        console.log("ä½¿ç”¨ Gemini å¤šäººå°è©± TTS ç”Ÿæˆå®Œæ•´å°è©±...");
        
        const synthesized = await synthesizeMultiSpeakerWithGemini(dialogLines, speakers);
        
        if (synthesized) {
          const byteCharacters = atob(synthesized.data);
          const pcmData = new Uint8Array(byteCharacters.length);
          for (let j = 0; j < byteCharacters.length; j++) {
            pcmData[j] = byteCharacters.charCodeAt(j);
          }
          
          const wavData = convertPCMToWAV(pcmData);
          const blob = new Blob([wavData], { type: 'audio/wav' });

          const link = document.createElement('a');
          link.href = URL.createObjectURL(blob);
          link.download = `gemini_podcast_full_conversation.wav`;
          document.body.appendChild(link);
          link.click();
          document.body.removeChild(link);
          URL.revokeObjectURL(link.href);

          dialogLines.forEach(line => {
            const lineDuration = line.text.length * 0.1;
            onAudioSegmentSynthesized(line.id, lineDuration);
          });
        }
      } else {
        console.log("ä½¿ç”¨é€è¡ŒéŸ³è¨Šç”Ÿæˆæ¨¡å¼...");
        
        const audioSegments: { name: string; data: Blob }[] = [];
        let hasErrorOccurred = false;

        for (let i = 0; i < dialogLines.length; i++) {
          const line = dialogLines[i];
          const speaker = speakers.find(s => s.id === line.speakerId);

          if (!speaker) {
            setError(`ç¬¬ ${i + 1} è¡Œå°è©±æ‰¾ä¸åˆ°ç™¼è¨€äººè¨­å®šã€‚`);
            hasErrorOccurred = true;
            break; 
          }
          
          try {
            const synthesized = await synthesizeSpeechInternal(line.text, speaker);

            if (synthesized) {
              const byteCharacters = atob(synthesized.data);
              const pcmData = new Uint8Array(byteCharacters.length);
              for (let j = 0; j < byteCharacters.length; j++) {
                pcmData[j] = byteCharacters.charCodeAt(j);
              }
              
              const wavData = convertPCMToWAV(pcmData);
              const blob = new Blob([wavData], { type: 'audio/wav' });
              
              const lineDuration = line.text.length * 0.1;
              onAudioSegmentSynthesized(line.id, lineDuration);

              const safeSpeakerName = speaker.name.replace(/[^\w\s\u4e00-\u9fa5]/gi, '').replace(/\s+/g, '_'); 
              const fileName = `podcast_segment_${String(i + 1).padStart(2, '0')}_${safeSpeakerName}.wav`;
              audioSegments.push({ name: fileName, data: blob });
            } else {
               setError(`ç¬¬ ${i + 1} è¡ŒèªéŸ³åˆæˆå¤±æ•—ï¼Œæœªæ”¶åˆ°éŸ³è¨Šå…§å®¹ã€‚`);
               hasErrorOccurred = true;
               break;
            }
          } catch (e) {
            console.error(`ç¬¬ ${i + 1} è¡ŒéŸ³é »åˆæˆéŒ¯èª¤:`, e);
            setError(`ç¬¬ ${i + 1} è¡ŒèªéŸ³åˆæˆå¤±æ•—: ${e instanceof Error ? e.message : "æœªçŸ¥éŒ¯èª¤"}`);
            hasErrorOccurred = true;
            break; 
          }
        } 

        if (!hasErrorOccurred && audioSegments.length > 0) {
          try {
            const zip = new JSZip();
            audioSegments.forEach(segment => {
              zip.file(segment.name, segment.data);
            });
            
            const zipBlob = await zip.generateAsync({ type: "blob" });
            const link = document.createElement('a');
            link.href = URL.createObjectURL(zipBlob);
            link.download = 'gemini_podcast_audio_segments.zip';
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
            URL.revokeObjectURL(link.href);
          } catch (e) {
            console.error("å‰µå»ºæˆ–ä¸‹è¼‰ZIPæª”æ¡ˆéŒ¯èª¤:", e);
            setError(`ç”Ÿæˆ ZIP å£“ç¸®æª”å¤±æ•—: ${e instanceof Error ? e.message : "æœªçŸ¥éŒ¯èª¤"}`);
          }
        }
      }
    } catch (e) {
      setError(`èªéŸ³åˆæˆå¤±æ•—: ${e instanceof Error ? e.message : "æœªçŸ¥éŒ¯èª¤"}`);
    } finally {
      setIsSynthesizingAudio(false);
    }
  }, [dialogLines, speakers, scriptMode, synthesizeMultiSpeakerWithGemini, synthesizeSpeechInternal, setError, setIsSynthesizingAudio, onAudioSegmentSynthesized]);

  const canDownloadTimedTranscript = dialogLines.length > 0 && 
                                   Object.keys(actualAudioDurations).length === dialogLines.length &&
                                   dialogLines.every(line => actualAudioDurations[line.id] !== undefined && actualAudioDurations[line.id] >= 0);

  return (
    <div 
      className={`lg:w-1/3 bg-slate-900 p-6 rounded-lg shadow-xl space-y-6 overflow-y-auto custom-scrollbar 
                 lg:sticky lg:top-4 ${panelHeightClass || ''}`}
    >
      <h2 className="text-lg font-semibold text-emerald-400 mb-1">4. åŸ·è¡Œèˆ‡è¨­å®š (Run & Settings)</h2>
      
      <div className="space-y-3">
        <label htmlFor="ai-model-display" className="block text-sm font-medium text-slate-300">AI æ–‡å­—æ¨¡å‹ (AI Text Model)</label>
        <div id="ai-model-display" className="bg-slate-800 p-3 rounded-md text-sm border border-slate-700">{GEMINI_MODEL_TEXT} (Text Generation)</div>
      
        <fieldset className="space-y-1">
            <legend className="block text-sm font-medium text-slate-300 mb-1">æ¨¡å¼ (Mode)</legend>
            <div className="grid grid-cols-2 gap-2">
              <Button onClick={() => setScriptMode(ScriptMode.SINGLE)} variant={scriptMode === ScriptMode.SINGLE ? 'primary' : 'secondary'} fullWidth aria-pressed={scriptMode === ScriptMode.SINGLE}>
                <UserIcon className="w-5 h-5 mr-2"/> å–®äººä¸»æŒ
              </Button>
              <Button onClick={() => setScriptMode(ScriptMode.MULTI)} variant={scriptMode === ScriptMode.MULTI ? 'primary' : 'secondary'} fullWidth aria-pressed={scriptMode === ScriptMode.MULTI}>
                <UsersIcon className="w-5 h-5 mr-2"/> å¤šäººå°è©±
              </Button>
            </div>
        </fieldset>
      </div>

      <AccordionSection title="èªéŸ³è¨­å®š (Voice Settings)" icon={<Cog8ToothIcon className="w-5 h-5 text-slate-400" />} defaultOpen={true} id="voice-settings-section">
        <div className="mb-4 p-3 bg-slate-800 rounded-md border border-emerald-600/50">
          <div className="flex items-center">
            <span className="w-2 h-2 rounded-full bg-emerald-400 mr-2"></span>
            <span className="text-emerald-400 font-semibold text-sm">ğŸš€ Gemini AI åŸç”Ÿ TTS å·²å•Ÿç”¨</span>
          </div>
          <p className="text-xs text-slate-400 mt-1">âœ¨ 30ç¨®é«˜å“è³ªèªéŸ³ | ğŸ­ æ™ºèƒ½å¤šäººå°è©± | ğŸŒ 24ç¨®èªè¨€æ”¯æ´ | ğŸ›ï¸ ç²¾ç´°èªéŸ³æ§åˆ¶</p>
        </div>

        {(scriptMode === ScriptMode.SINGLE ? [speakers[0]] : speakers).map((speaker, originalIndex) => {
          const speakerArrayIndex = scriptMode === ScriptMode.SINGLE ? speakers.findIndex(s => s.id === speaker.id) : originalIndex;
          if (!speaker) return null; 

          return (
            <div key={speaker.id} className="p-3 border border-slate-700 rounded-md bg-slate-800">
              <div className="flex items-center mb-2">
                <span className={`w-3 h-3 rounded-full ${speaker.dotColor} mr-2`}></span>
                <h4 className="font-semibold text-sm text-slate-300">ç™¼è¨€äºº {originalIndex + 1} è¨­å®š</h4>
              </div>
              
              <TextInput
                label="åç¨± (Name)"
                id={`speaker-name-${speaker.id}`}
                value={speaker.name}
                onChange={(e) => handleSpeakerChange(speakerArrayIndex, 'name', e.target.value)}
                placeholder={`ä¾‹å¦‚ï¼šä¸»æŒäºº ${originalIndex + 1}`}
              />
              
              <div className="flex items-end space-x-2">
                <Select
                  label="ğŸ¤ Gemini AI åŸç”ŸèªéŸ³ (30ç¨®é«˜å“è³ªé¸é …)"
                  id={`speaker-voice-style-${speaker.id}`}
                  value={speaker.voice} 
                  onChange={(e) => handleSpeakerChange(speakerArrayIndex, 'voice', e.target.value)}
                  options={AVAILABLE_VOICES.map(v => ({ value: v.id, label: v.name }))}
                  className="flex-grow"
                  helperText="âœ¨ ä½¿ç”¨ Gemini AI åŸç”ŸèªéŸ³æŠ€è¡“ï¼Œæ”¯æ´å¤šäººå°è©±ã€é¢¨æ ¼æ§åˆ¶å’Œ 24 ç¨®èªè¨€ã€‚"
                />
                <Button 
                  onClick={() => handlePreviewVoice(speakerArrayIndex)} 
                  variant="outline" 
                  size="md" 
                  className="mb-3 flex-shrink-0"
                  aria-label={`é è¦½ ${speaker.name} çš„ Gemini AI èªéŸ³`}
                  disabled={isSynthesizingAudio}
                >
                  {previewingSpeakerIndex === speakerArrayIndex && isSynthesizingAudio
                    ? <Spinner />
                    : <PlayCircleIcon className="w-5 h-5" />}
                </Button>
              </div>

              {/* ğŸ†• æ–°å¢èªéŸ³å“è³ªæ§åˆ¶ */}
              <div className="mt-3 space-y-2">
                <h5 className="text-xs font-medium text-slate-400">ğŸ­ èªéŸ³é¢¨æ ¼è¨­å®š (Voice Style Controls)</h5>
                
                <div className="grid grid-cols-2 gap-2">
                  <Select
                    label="æƒ…ç·’"
                    id={`speaker-emotion-${speaker.id}`}
                    value={speaker.emotion || 'neutral'}
                    onChange={(e) => handleSpeakerChange(speakerArrayIndex, 'emotion', e.target.value)}
                    options={EMOTION_OPTIONS}
                  />
                  <Select
                    label="èªé€Ÿ"
                    id={`speaker-pace-${speaker.id}`}
                    value={speaker.pace || 'normal'}
                    onChange={(e) => handleSpeakerChange(speakerArrayIndex, 'pace', e.target.value)}
                    options={PACE_OPTIONS}
                  />
                </div>
                
                <div className="grid grid-cols-2 gap-2">
                  <Select
                    label="éŸ³èª¿"
                    id={`speaker-tone-${speaker.id}`}
                    value={speaker.tone || 'normal'}
                    onChange={(e) => handleSpeakerChange(speakerArrayIndex, 'tone', e.target.value)}
                    options={TONE_OPTIONS}
                  />
                  <Select
                    label="é¢¨æ ¼"
                    id={`speaker-style-${speaker.id}`}
                    value={speaker.style || 'normal'}
                    onChange={(e) => handleSpeakerChange(speakerArrayIndex, 'style', e.target.value)}
                    options={STYLE_OPTIONS}
                  />
                </div>
                
                {/* ğŸ¯ èªéŸ³è¨­å®šé è¦½æç¤º */}
                {(speaker.emotion !== 'neutral' || speaker.pace !== 'normal' || speaker.tone !== 'normal' || speaker.style !== 'normal') && (
                  <div className="mt-2 p-2 bg-blue-900/30 border border-blue-600/50 rounded-md">
                    <p className="text-xs text-blue-300">
                      ğŸ¨ <strong>èªéŸ³æ•ˆæœé è¦½ï¼š</strong>
                      {speaker.emotion && speaker.emotion !== 'neutral' && ` ${EMOTION_OPTIONS.find(e => e.value === speaker.emotion)?.label}`}
                      {speaker.pace && speaker.pace !== 'normal' && ` ${PACE_OPTIONS.find(p => p.value === speaker.pace)?.label}`}
                      {speaker.tone && speaker.tone !== 'normal' && ` ${TONE_OPTIONS.find(t => t.value === speaker.tone)?.label}`}
                      {speaker.style && speaker.style !== 'normal' && ` ${STYLE_OPTIONS.find(s => s.value === speaker.style)?.label}`}
                    </p>
                  </div>
                )}
              </div>
            </div>
          );
        })}
      </AccordionSection>
      
      <div className="space-y-3 pt-3">
        <Button onClick={onGenerateScript} disabled={isLoading || isSynthesizingAudio} fullWidth variant="primary" aria-label="Generate podcast script">
          {(isLoading && !isSynthesizingAudio) ? <Spinner /> : <SparklesIcon className="w-5 h-5 mr-2" />} ç”Ÿæˆè…³æœ¬
        </Button>
         <Button onClick={onGenerateSeoMeta} disabled={isLoading || isSynthesizingAudio || dialogLines.length === 0} fullWidth variant="secondary" aria-label="Generate SEO metadata">
           {(isLoading && !isSynthesizingAudio) ? <Spinner /> : <SparklesIcon className="w-5 h-5 mr-2" />} ç”Ÿæˆ SEO Meta
        </Button>
      </div>

      <AccordionSection title="ç”¢å‡ºèˆ‡ç™¼ä½ˆ (Output & Publishing)" icon={<DocumentTextIcon className="w-5 h-5 text-slate-400" />} id="output-publishing-section">
        {seoMeta && (
          <div className="bg-slate-800 p-3 rounded-md border border-slate-700">
            <h4 className="font-semibold text-sm text-sky-400 mb-1">SEO Meta:</h4>
            <p className="text-xs text-slate-300"><strong>Title:</strong> {seoMeta.title}</p>
            <p className="text-xs text-slate-300"><strong>Description:</strong> {seoMeta.description}</p>
          </div>
        )}
        <Button onClick={onDownloadScriptText} fullWidth variant="outline" aria-label="ä¸‹è¼‰è…³æœ¬æ–‡å­— (TXT)" disabled={dialogLines.length === 0 || isSynthesizingAudio}>
          <DocumentTextIcon className="w-5 h-5 mr-2"/> ä¸‹è¼‰è…³æœ¬æ–‡å­— (TXT)
        </Button>
        <Button 
          onClick={onDownloadTimedTranscriptSrt} 
          fullWidth 
          variant="outline" 
          aria-label="ä¸‹è¼‰æ™‚é–“ç¢¼é€å­—ç¨¿ (SRT)" 
          disabled={!canDownloadTimedTranscript || isSynthesizingAudio}
          title={!canDownloadTimedTranscript ? "è«‹å…ˆã€Œç”¢ç”Ÿ AI Podcast èªéŸ³ã€ä»¥ç²å–ç²¾ç¢ºæ™‚é–“æˆ³ã€‚" : "ä¸‹è¼‰ SRT æ ¼å¼çš„æ™‚é–“ç¢¼é€å­—ç¨¿"}
        >
          <ClockIcon className="w-5 h-5 mr-2"/> ä¸‹è¼‰æ™‚é–“ç¢¼é€å­—ç¨¿ (SRT)
        </Button>
        <Button 
          onClick={handleGenerateFullPodcastAudio} 
          fullWidth 
          variant="outline" 
          aria-label="ç”¢ç”Ÿ AI Podcast èªéŸ³" 
          disabled={dialogLines.length === 0 || isSynthesizingAudio}
        >
         {isSynthesizingAudio ? <Spinner/> : <MusicalNoteIcon className="w-5 h-5 mr-2"/>} 
         ğŸ­ ç”¢ç”Ÿ AI Podcast èªéŸ³ (æ™ºèƒ½å¤šäººå°è©± + ç²¾ç´°é¢¨æ ¼æ§åˆ¶)
        </Button>
        <TextInput
          label="RSS Feed ç™¼ä½ˆç¶²å€ (RSS Feed URL - for reference)"
          id="rss-feed-url"
          value={rssFeedUrl}
          onChange={(e) => setRssFeedUrl(e.target.value)}
          placeholder="https://anchor.fm/s/your-id/podcast/rss"
          helperText="æ­¤æ¬„ä½åƒ…ä¾›è¨˜éŒ„ï¼Œç›®å‰ä¸æ”¯æ´è‡ªå‹•ä¸Šå‚³ã€‚"
        />
      </AccordionSection>
    </div>
  );
};